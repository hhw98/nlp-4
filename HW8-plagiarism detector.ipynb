{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "import time, timeit\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = r\"C:\\Users\\hyh6hhy\\Desktop\\nlp-4\\sqlResult_1558435.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(fname, encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>feature</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>89617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"37\"...</td>\n",
       "      <td>小米MIUI 9首批机型曝光：共计15款</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623597.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>89616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"15\"...</td>\n",
       "      <td>骁龙835在Windows 10上的性能表现有望改善</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623599.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>89615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"18\"...</td>\n",
       "      <td>一加手机5细节曝光：3300mAh、充半小时用1天</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623601.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>89614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>新华社</td>\n",
       "      <td>这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄\\r\\n</td>\n",
       "      <td>{\"type\":\"国际新闻\",\"site\":\"环球\",\"commentNum\":\"0\",\"j...</td>\n",
       "      <td>葡森林火灾造成至少62人死亡 政府宣布进入紧急状态（组图）</td>\n",
       "      <td>http://world.huanqiu.com/hot/2017-06/10866126....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>89613</td>\n",
       "      <td>胡淑丽_MN7479</td>\n",
       "      <td>深圳大件事</td>\n",
       "      <td>（原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……）\\r\\n@深圳交警微博称：昨日清...</td>\n",
       "      <td>{\"type\":\"新闻\",\"site\":\"网易热门\",\"commentNum\":\"978\",...</td>\n",
       "      <td>44岁女子约网友被拒暴雨中裸奔 交警为其披衣相随</td>\n",
       "      <td>http://news.163.com/17/0618/00/CN617P3Q0001875...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      author                  source  \\\n",
       "0  89617         NaN  快科技@http://www.kkj.cn/   \n",
       "1  89616         NaN  快科技@http://www.kkj.cn/   \n",
       "2  89615         NaN  快科技@http://www.kkj.cn/   \n",
       "3  89614         NaN                     新华社   \n",
       "4  89613  胡淑丽_MN7479                   深圳大件事   \n",
       "\n",
       "                                             content  \\\n",
       "0  此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...   \n",
       "1  骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...   \n",
       "2  此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...   \n",
       "3    这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄\\r\\n   \n",
       "4  （原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……）\\r\\n@深圳交警微博称：昨日清...   \n",
       "\n",
       "                                             feature  \\\n",
       "0  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"37\"...   \n",
       "1  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"15\"...   \n",
       "2  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"18\"...   \n",
       "3  {\"type\":\"国际新闻\",\"site\":\"环球\",\"commentNum\":\"0\",\"j...   \n",
       "4  {\"type\":\"新闻\",\"site\":\"网易热门\",\"commentNum\":\"978\",...   \n",
       "\n",
       "                           title  \\\n",
       "0           小米MIUI 9首批机型曝光：共计15款   \n",
       "1     骁龙835在Windows 10上的性能表现有望改善   \n",
       "2      一加手机5细节曝光：3300mAh、充半小时用1天   \n",
       "3  葡森林火灾造成至少62人死亡 政府宣布进入紧急状态（组图）   \n",
       "4       44岁女子约网友被拒暴雨中裸奔 交警为其披衣相随   \n",
       "\n",
       "                                                 url  \n",
       "0     http://www.cnbeta.com/articles/tech/623597.htm  \n",
       "1     http://www.cnbeta.com/articles/tech/623599.htm  \n",
       "2     http://www.cnbeta.com/articles/tech/623601.htm  \n",
       "3  http://world.huanqiu.com/hot/2017-06/10866126....  \n",
       "4  http://news.163.com/17/0618/00/CN617P3Q0001875...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature    {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"37\"...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0,['feature']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add clock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clock(func):\n",
    "    def clocked(*args, **kwargs):\n",
    "        t0 = timeit.default_timer()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = timeit.default_timer() - t0\n",
    "        name = func.__name__\n",
    "        arg_str = ', '.join(repr(arg) for arg in args)\n",
    "        print(elapsed,'s')\n",
    "        #print('[%0.8fs] %s(%s) -> %r' % (elapsed, name, arg_str, result))\n",
    "        return result\n",
    "    return clocked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT: Which is more useful, more efficient ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.277370116 s\n",
      "content (38729226, 432.1927665130397)\n",
      "2.687388330000001 s\n",
      "feature (53450994, 596.4780439901351)\n",
      "3.8331849430000027 s\n",
      "title (2123231, 23.69386570845097)\n",
      "2.293857959999997 s\n",
      "author (505494, 5.6409815759225985)\n",
      "2.360930752999998 s\n",
      "url (7472901, 83.39267500641662)\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def get_size(data, attributes):\n",
    "    size = 0\n",
    "    data = data[attributes]\n",
    "    for i in range(len(data)):\n",
    "        if isinstance(data[i],str):\n",
    "            size = size + len(data[i])\n",
    "    return size, size/len(data)\n",
    "\n",
    "attributes = ['content','feature', 'title','author','url']\n",
    "attr_choosen = ['content']\n",
    "#attr_choosen = ['content','feature', 'title','author','url']\n",
    "attr_choosen = ['content']\n",
    "show = [print( i, get_size(data,i)) for i in attributes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不平衡数据处理：重复但有过拟合风险；剪掉浪费；可以重组。imbalanced 用作baseline。TF-IDF不能像word2vec展示词之间的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8778051801676133"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xinhua_news = data[data[\"source\"] == \"新华社\"]\n",
    "len(xinhua_news)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>feature</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>56707</td>\n",
       "      <td>32905</td>\n",
       "      <td>殷博古</td>\n",
       "      <td>新华社</td>\n",
       "      <td>新华社照片，华盛顿，2017年5月10日\\n（国际）（3）美国和格鲁吉亚签署情报保护协定\\n...</td>\n",
       "      <td>{\"type\":\"政治法律\",\"site\":\"新华社\",\"url\":\"http://home...</td>\n",
       "      <td>（国际）（3）美国和格鲁吉亚签署情报保护协定</td>\n",
       "      <td>http://home.xinhua-news.com/gdsdetailxhsnew/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39843</td>\n",
       "      <td>49769</td>\n",
       "      <td>刘秀玲</td>\n",
       "      <td>新华社</td>\n",
       "      <td>【新华社微特稿】《西日本新闻》２４日援引内部人士的话报道，旨在为“慰安妇”受害者提供所谓...</td>\n",
       "      <td>{\"type\":\"政治法律\",\"site\":\"新华社\",\"url\":\"http://home...</td>\n",
       "      <td>【微特稿·时事与军事】日韩“慰安妇”基金面临夭折？</td>\n",
       "      <td>http://home.xinhua-news.com/gdsdetailxhsnew/19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76148</td>\n",
       "      <td>13464</td>\n",
       "      <td>毛伟豪</td>\n",
       "      <td>新华社</td>\n",
       "      <td>新华社北京５月２６日电（记者毛伟豪）从北京到保定，１５０公里的距离，４２分钟的高铁车程。...</td>\n",
       "      <td>{\"type\":\"社会\",\"site\":\"新华社\",\"url\":\"http://home.x...</td>\n",
       "      <td>（京津冀在行动）１３８名北京儿科专家为何坐高铁跨城上班？</td>\n",
       "      <td>http://home.xinhua-news.com/gdsdetailxhsnew/21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44751</td>\n",
       "      <td>44861</td>\n",
       "      <td>张莹</td>\n",
       "      <td>新华社</td>\n",
       "      <td>新华社布鲁塞尔４月２８日新媒体专电欧盟委员会２７日发布“欧洲城市水资源管理地图集”，详细展示...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"新华社\",\"url\":\"http://home.x...</td>\n",
       "      <td>（新华简讯）欧盟发布“欧洲城市水资源管理地图集”</td>\n",
       "      <td>http://home.xinhua-news.com/gdsdetailxhsnew/19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18437</td>\n",
       "      <td>71175</td>\n",
       "      <td>J. Luis Cuesta / Cordon P/SIPA</td>\n",
       "      <td>新华社</td>\n",
       "      <td>新华社照片，外代，2017年4月6日\\n（外代二线）马德里动物园的大熊猫“竹莉娜”首次与观众...</td>\n",
       "      <td>{\"type\":\"其它\",\"site\":\"新华社\",\"url\":\"http://home.x...</td>\n",
       "      <td>[12]（外代二线）马德里动物园的大熊猫“竹莉娜”首次与观众正式见面</td>\n",
       "      <td>http://home.xinhua-news.com/gdsdetailxhsnew/18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                          author source  \\\n",
       "56707  32905                             殷博古    新华社   \n",
       "39843  49769                             刘秀玲    新华社   \n",
       "76148  13464                             毛伟豪    新华社   \n",
       "44751  44861                              张莹    新华社   \n",
       "18437  71175  J. Luis Cuesta / Cordon P/SIPA    新华社   \n",
       "\n",
       "                                                 content  \\\n",
       "56707  新华社照片，华盛顿，2017年5月10日\\n（国际）（3）美国和格鲁吉亚签署情报保护协定\\n...   \n",
       "39843  　　【新华社微特稿】《西日本新闻》２４日援引内部人士的话报道，旨在为“慰安妇”受害者提供所谓...   \n",
       "76148  　　新华社北京５月２６日电（记者毛伟豪）从北京到保定，１５０公里的距离，４２分钟的高铁车程。...   \n",
       "44751  新华社布鲁塞尔４月２８日新媒体专电欧盟委员会２７日发布“欧洲城市水资源管理地图集”，详细展示...   \n",
       "18437  新华社照片，外代，2017年4月6日\\n（外代二线）马德里动物园的大熊猫“竹莉娜”首次与观众...   \n",
       "\n",
       "                                                 feature  \\\n",
       "56707  {\"type\":\"政治法律\",\"site\":\"新华社\",\"url\":\"http://home...   \n",
       "39843  {\"type\":\"政治法律\",\"site\":\"新华社\",\"url\":\"http://home...   \n",
       "76148  {\"type\":\"社会\",\"site\":\"新华社\",\"url\":\"http://home.x...   \n",
       "44751  {\"type\":\"科技\",\"site\":\"新华社\",\"url\":\"http://home.x...   \n",
       "18437  {\"type\":\"其它\",\"site\":\"新华社\",\"url\":\"http://home.x...   \n",
       "\n",
       "                                    title  \\\n",
       "56707              （国际）（3）美国和格鲁吉亚签署情报保护协定   \n",
       "39843           【微特稿·时事与军事】日韩“慰安妇”基金面临夭折？   \n",
       "76148        （京津冀在行动）１３８名北京儿科专家为何坐高铁跨城上班？   \n",
       "44751            （新华简讯）欧盟发布“欧洲城市水资源管理地图集”   \n",
       "18437  [12]（外代二线）马德里动物园的大熊猫“竹莉娜”首次与观众正式见面   \n",
       "\n",
       "                                                     url  \n",
       "56707  http://home.xinhua-news.com/gdsdetailxhsnew/20...  \n",
       "39843  http://home.xinhua-news.com/gdsdetailxhsnew/19...  \n",
       "76148  http://home.xinhua-news.com/gdsdetailxhsnew/21...  \n",
       "44751  http://home.xinhua-news.com/gdsdetailxhsnew/19...  \n",
       "18437  http://home.xinhua-news.com/gdsdetailxhsnew/18...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"source\"] = data[\"source\"].fillna(\"\")\n",
    "data_pos = data[data[\"source\"].str.contains(\"新华社\")]\n",
    "data_neg = data[data[\"source\"].str.contains(\"新华社\") == 0]\n",
    "NUM = 6000\n",
    "data_pos = data_pos.sample(n = (int)(NUM/2))\n",
    "data_neg = data_neg.sample(n = (int)(NUM/2))\n",
    "\n",
    "data_sampled = data_pos.append(data_neg)\n",
    "\n",
    "data_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去标点，加label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\hyh6hhy\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.409 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def cut(string):\n",
    "    return \" \".join(jieba.cut(re.sub(r'[^\\w\\s]', \" \", string.strip())))   #string\n",
    "    #return ' '.join(jieba.cut(re.sub(r'[^\\w\\s]',' ',string.strip())))\n",
    "def preprocessing(data):\n",
    "    for attri in attributes:\n",
    "        data[attri] = data[attri].fillna('').apply(cut)  #fillna('').\n",
    "    data['is_xinhua'] = np.where(data['source'].str.contains('新华'), 1, 0) #.str.contains('新华')\n",
    "    x_inputs = data.loc[: ,attr_choosen]\n",
    "    y_inputs = data['is_xinhua']\n",
    "    return x_inputs, y_inputs\n",
    "x_inputs, y_inputs = preprocessing(data_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_inputs['content'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation with tf-idfvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1364556289999967 s\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def vectorize(x_inputs):\n",
    "    vectorizer = TfidfVectorizer(max_features=5000, token_pattern=r\"(?u)\\b\\w+\\b\", max_df = 1.0)# (?u)进入re.u，unicode匹配模式，https://stackoverflow.com/questions/35043085/what-does-u-do-in-a-regex\n",
    "    #vectorizer = TfidfVectorizer(token_pattern = \"(?u)\\b\\w+\\b\",max_features=5000, max_df = 1.0)\n",
    "    matrix = None\n",
    "    for attri in attr_choosen:\n",
    "        #print(x_inputs[attri].values)\n",
    "        #X = vectorizer.fit_transform(x_inputs[attri].values)\n",
    "        vec_fea = vectorizer.fit_transform(x_inputs[attri].values)\n",
    "        #print(\"vocabulary\\n\",vectorizer.vocabulary_, len(vectorizer.vocabulary_))\n",
    "        #print(\"stop_words\\n\",vectorizer.stop_words_, len(vectorizer.stop_words_))\n",
    "        \n",
    "        if matrix == None:\n",
    "            matrix = vec_fea\n",
    "        else:\n",
    "            matrix = np.hstack((matrix, vec_fea))\n",
    "    return matrix\n",
    "\n",
    "x_vecs = vectorize(x_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56707    1\n",
       "39843    1\n",
       "76148    1\n",
       "44751    1\n",
       "18437    1\n",
       "        ..\n",
       "9870     0\n",
       "2544     0\n",
       "902      0\n",
       "7584     0\n",
       "4523     1\n",
       "Name: is_xinhua, Length: 6000, dtype: int32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test, y_train, y_test = train_test_split(\n",
    "    x_vecs , y_inputs, train_size = 0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(model, x, y):\n",
    "    y_pred = model.predict(x)\n",
    "    print(\"f1 score is {}\".format(f1_score(y, y_pred)))\n",
    "    print(\"accuracy score is {}\".format(accuracy_score(y,y_pred)))\n",
    "    print(\"precision score is {}\".format(precision_score(y, y_pred)))\n",
    "    print(\"recall score is {}\".format(recall_score(y, y_pred)))\n",
    "    print(\"roc auc score is {}\".format(roc_auc_score(y, y_pred)))\n",
    "    print(\"confusion matrix :\\n {}\".format(confusion_matrix(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06580940599999963 s\n",
      "f1 score is 0.6533333333333333\n",
      "accuracy score is 0.74\n",
      "precision score is 0.9966101694915255\n",
      "recall score is 0.4859504132231405\n",
      "roc auc score is 0.7421348704771165\n",
      "confusion matrix :\n",
      " [[594   1]\n",
      " [311 294]]\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def KNN(x_train, y_train):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "    model = neigh.fit(x_train, y_train)\n",
    "    return model\n",
    "get_performance(KNN(x_train, y_train),x_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n",
      "8.043894962999957 s\n",
      "f1 score is 0.7655786350148367\n",
      "accuracy score is 0.8025\n",
      "precision score is 0.9532019704433498\n",
      "recall score is 0.6396694214876033\n",
      "roc auc score is 0.8038683241891798\n",
      "confusion matrix :\n",
      " [[576  19]\n",
      " [218 387]]\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_neighbors':list(range(1,6))}\n",
    "@clock\n",
    "def KNN(x_train, y_train):\n",
    "    clf = KNeighborsClassifier()\n",
    "    grid = GridSearchCV(clf, parameters, cv=2, scoring = 'accuracy', n_jobs = -1)\n",
    "    clf = grid.fit(x_train, y_train)\n",
    "    #clf.fit(x_train, y_train)\n",
    "    print(clf.best_params_)\n",
    "    return clf\n",
    "get_performance(KNN(x_train, y_train),x_test, y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@clock\n",
    "def LReg(x_train, y_train):\n",
    "    reg = LinearRegression().fit(x_train, y_train)\n",
    "    \n",
    "    return reg\n",
    "#get_performance(LReg(x_train, y_train), x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10947630900000149 s\n",
      "f1 score is 0.976311336717428\n",
      "accuracy score is 0.9766666666666667\n",
      "precision score is 1.0\n",
      "recall score is 0.9537190082644628\n",
      "roc auc score is 0.9768595041322314\n",
      "confusion matrix :\n",
      " [[595   0]\n",
      " [ 28 577]]\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def logreg(x_train, y_train):\n",
    "    clf = LogisticRegression(random_state=0, solver='liblinear').fit(x_train, y_train)\n",
    "    return clf\n",
    "get_performance(logreg(x_train, y_train), x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'liblinear'}\n",
      "0.4369922470000347 s\n",
      "f1 score is 0.976311336717428\n",
      "accuracy score is 0.9766666666666667\n",
      "precision score is 1.0\n",
      "recall score is 0.9537190082644628\n",
      "roc auc score is 0.9768595041322314\n",
      "confusion matrix :\n",
      " [[595   0]\n",
      " [ 28 577]]\n"
     ]
    }
   ],
   "source": [
    "parameters = {'solver':('liblinear', 'sag','saga')}\n",
    "@clock\n",
    "def logreg(x_train, y_train):\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    grid = GridSearchCV(clf, parameters, cv=2, scoring = 'accuracy', n_jobs = -1)\n",
    "    clf = grid.fit(x_train, y_train)\n",
    "    #clf.fit(x_train, y_train)\n",
    "    print(clf.best_params_)\n",
    "    return clf\n",
    "get_performance(logreg(x_train, y_train), x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyh6hhy\\Miniconda3\\envs\\stanfordnlp\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.38155877600002 s\n",
      "f1 score is 0.6703601108033241\n",
      "accuracy score is 0.5041666666666667\n",
      "precision score is 0.5041666666666667\n",
      "recall score is 1.0\n",
      "roc auc score is 0.5\n",
      "confusion matrix :\n",
      " [[  0 595]\n",
      " [  0 605]]\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def svm(x_train, y_train):\n",
    "    clf = SVC(random_state=0).fit(x_train, y_train)\n",
    "    return clf\n",
    "get_performance(svm(x_train, y_train), x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear'}\n",
      "48.48124402500025 s\n",
      "f1 score is 0.9848993288590604\n",
      "accuracy score is 0.985\n",
      "precision score is 1.0\n",
      "recall score is 0.9702479338842975\n",
      "roc auc score is 0.9851239669421488\n",
      "confusion matrix :\n",
      " [[595   0]\n",
      " [ 18 587]]\n"
     ]
    }
   ],
   "source": [
    "parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "\n",
    "@clock\n",
    "def svm(x_train, y_train):\n",
    "    clf = SVC(random_state=0)\n",
    "    grid = GridSearchCV(clf, parameters, cv=2, scoring = 'accuracy', n_jobs = -1)\n",
    "    clf = grid.fit(x_train, y_train)\n",
    "    print(clf.best_params_)\n",
    "    return clf\n",
    "get_performance(svm(x_train, y_train), x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0314007970000603 s\n",
      "f1 score is 0.8575624082232012\n",
      "accuracy score is 0.8383333333333334\n",
      "precision score is 0.7714663143989432\n",
      "recall score is 0.9652892561983472\n",
      "roc auc score is 0.8372664768386694\n",
      "confusion matrix :\n",
      " [[422 173]\n",
      " [ 21 584]]\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def gnb(x_train, y_train):\n",
    "    gnb = GaussianNB().fit(x_train.toarray(), y_train) #x needed to be dense\n",
    "    return gnb\n",
    "get_performance(gnb(x_train, y_train), x_test.toarray(),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-09}\n",
      "7.489706000000297 s\n",
      "f1 score is 0.8575624082232012\n",
      "accuracy score is 0.8383333333333334\n",
      "precision score is 0.7714663143989432\n",
      "recall score is 0.9652892561983472\n",
      "roc auc score is 0.8372664768386694\n",
      "confusion matrix :\n",
      " [[422 173]\n",
      " [ 21 584]]\n"
     ]
    }
   ],
   "source": [
    "parameters = {'var_smoothing':[1e-08, 1e-09, 1e-10, 1e-09-11]}\n",
    "\n",
    "@clock\n",
    "def gnb(x_train, y_train):\n",
    "    gnb = GaussianNB()\n",
    "    grid = GridSearchCV(gnb, parameters, cv=2, scoring = 'accuracy', n_jobs = -1)\n",
    "    gnb = grid.fit(x_train.toarray(), y_train) #x needed to be dense\n",
    "    print(gnb.best_params_)\n",
    "    return gnb\n",
    "get_performance(gnb(x_train, y_train), x_test.toarray(),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5752719710003475 s\n",
      "f1 score is 0.977850697292863\n",
      "accuracy score is 0.9775\n",
      "precision score is 0.9706840390879479\n",
      "recall score is 0.9851239669421488\n",
      "roc auc score is 0.9774359330509063\n",
      "confusion matrix :\n",
      " [[577  18]\n",
      " [  9 596]]\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def dec_tree(x_train, y_train):\n",
    "    clf = tree.DecisionTreeClassifier().fit(x_train, y_train) \n",
    "    return clf\n",
    "get_performance(dec_tree(x_train, y_train), x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35335307400009697 s\n",
      "f1 score is 0.9107142857142858\n",
      "accuracy score is 0.9166666666666666\n",
      "precision score is 0.9902912621359223\n",
      "recall score is 0.8429752066115702\n",
      "roc auc score is 0.9172859226335163\n",
      "confusion matrix :\n",
      " [[590   5]\n",
      " [ 95 510]]\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def RF(x_train, y_train):\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0).fit(x_train, y_train) \n",
    "    return clf\n",
    "get_performance(RF(x_train, y_train), x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 18, 'n_estimators': 50}\n",
      "63.33335296699988 s\n",
      "f1 score is 0.9814814814814815\n",
      "accuracy score is 0.9816666666666667\n",
      "precision score is 1.0\n",
      "recall score is 0.9636363636363636\n",
      "roc auc score is 0.9818181818181818\n",
      "confusion matrix :\n",
      " [[595   0]\n",
      " [ 22 583]]\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators':[50, 100,200],'max_depth':[5,8,11,15,18]}\n",
    "\n",
    "@clock\n",
    "def RF(x_train, y_train):\n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "    grid = GridSearchCV(clf, parameters, cv=2, scoring = 'accuracy', n_jobs = -1)\n",
    "    clf = grid.fit(x_train.toarray(), y_train) \n",
    "    print(clf.best_params_)\n",
    "    return clf\n",
    "get_performance(RF(x_train, y_train), x_test.toarray(),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
